x <- readr::read_csv(url)
View(x)
x <- read.table(url)
x <- read.csv(url)
View(x)
x <- download.file(url, destfile = "C:\\Users\\benba\\Documents\\Defusing Disasters\\DeGAUSS\\TEST\\test.csv", method = "wget")
download.file(url, destfile = "C:\\Users\\benba\\Documents\\Defusing Disasters\\DeGAUSS\\TEST\\test.csv", method = "wget")
download.file(url, destfile = "C:\\Users\\benba\\Documents\\Defusing Disasters\\DeGAUSS\\TEST\\test.csv")
con <- curl(url)
con
open(con)
out <- readLines(con, n = 3)
out
out <- readLines(con, n = 10)
out
close(con)
con <- curl(url)
open(con)
out <- readLines(con)
close(con)
out
x <- as.data.frame(out[8:9])
View(x)
# Let's try downloading Daymet data a different way, scraping it directly from the web
# Here's some documentation: https://daymet.ornl.gov/web_services#single
# Loading necessary packages
library(curl)
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
library(tidyverse)
# Importing this file back into R, only keeping the rows that I want
daymet_data <- read_csv("Daymet Data.csv")
View(daymet_data)
?read_csv
# Importing this file back into R, only keeping the rows that I want
daymet_data <- read_csv("Daymet Data.csv", skip = 7)
View(daymet_data)
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
?download.file
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
# Importing this file back into R, only keeping the rows that I want
daymet_data <- read_csv("Daymet Data.csv", skip = 7)
View(daymet_data)
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
connection
open(connection)
# Streaming the data
output <- readLines(connection)
# Closing the streaming connection
close(connection)
output
str(output)
# Pulling out the data of interest
str_detect(output, "year")
output
as.data.frame(output)
# Pulling out the data of interest
str_detect(output, "year,yday")
# Pulling out the data of interest
x <- output[str_detect(output, "year,yday")]
x
# Pulling out the data of interest
x <- output[str_detect(output, "year,yday"):,]
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday\\w+$")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*\n")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*|year,yday.*\n.*")
x
output
# Pulling out the data of interest
x <- str_extract(output, "year,yday.* \n")
x
str_detect(output, "year,yday")
output[str_detect(output, "year,yday")]
output[str_detect(output, "year,yday"):]
list(output)
# Pulling out the data of interest
output <- as.list(output)
output
x <- str_extract(output, "year,yday.*")
x
rm(x)
output[str_detect(output, "year,yday"):]
tail(output, -2)
tail(output, 2)
tail(output, 2)
rm(output, daymet_data, connection)
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
output[str_detect(output, "year,yday")]
# Pulling out the data of interest
output_length <- length(output)
output_length
data_position <- str_detect(output, "year,yday")
str_detect(data_position, TRUE)
str_detect(data_position, "TRUE")
data_position
str_locate(output, "year,yday")
str_locate_all(output, "year,yday")
str_match(output, "year,yday")
str_match_all(output, "year,yday")
data_position <- str_locate(output, "year,yday")
View(data_position)
match(output, "year,yday")
x <- str_detect(output, "year,yday")
x
match(x, TRUE)
match(TRUE, x)
# Pulling out the data of interest
output_length <- length(output)
rm(x)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail(output, 2)
head(output, 2)
tail_position <- output_length - data_position
tail_position
tail(output, 1)
tail(output, 2)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
output
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "How to")
data_string
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
tail_position
tail(output, 4)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "How to")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
output
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
# Splitting the data strings
str_split(daymet_data, ",")
# Splitting the data strings
x <- str_split(daymet_data, ",")
View(x)
# Splitting the data strings
daymet_data <- as_tibble(daymet_data)
rm(x)
View(daymet_data)
separate_wider_delim(daymet_data, delim = ",")
separate_wider_delim(daymet_data, cols = value, delim = ",")
separate_wider_delim(daymet_data, cols = value, names = NULL, delim = ",")
separate_wider_delim(daymet_data, cols = value, names = Var, delim = ",")
separate_wider_delim(daymet_data, cols = value, names = "Var", delim = ",")
View(daymet_data)
separate_wider_delim(daymet_data, cols = value, names = c("Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "Var9"), delim = ",")
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- as_tibble(daymet_data)
View(daymet_data)
x <- str_split(daymet_data, ",")
View(x)
daymet_data <- tail(output, tail_position)
# Splitting the data strings
x <- str_split(daymet_data, ",")
daymet_data <- as_tibble(daymet_data)
View(x)
length(x)
length(x[[1]])
daymet_data <- tail(output, tail_position)
daymet_data
# Splitting the data strings
num_values <- str_split(daymet_data[1], ",")
rm(x)
View(num_values)
# Splitting the data strings
num_values <- length(str_split(daymet_data[1], ","))
# Splitting the data strings
num_values <- length(str_split(daymet_data[1], ",")[[1]])
daymet_data <- tail(output, tail_position)
daymet_data
str_split(daymet_data[1], ",")
daymet_data[[1]]
str_split(daymet_data[[1]], ",")
length(str_split(daymet_data[[1]], ","))
daymet_data[[1]]
daymet_data[[1]]
str_split(daymet_data[[1]], ",")
str_split(daymet_data[[1]], ",", simplify = TRUE)
length(str_split(daymet_data[[1]], ",", simplify = TRUE))
str_split(daymet_data, ",", simplify = TRUE)
str_split(daymet_data, ",", simplify = TRUE)
x <- str_split(daymet_data, ",", simplify = TRUE)
View(x)
x <- as_tibble(x)
View(x)
row_to_names(x)
row_to_names(x)
library(janitor)
row_to_names(x)
?row_to_names
row_to_names(x, row_number = 1)
rm(x)
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
View(daymet_data)
daymet_data <- as_tibble(daymet_data)
View(daymet_data)
daymet_data <- row_to_names(daymet_data, row_number = 1)
View(daymet_data)
str(daymet_data)
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
str(daymet_data)
View(daymet_data)
View(daymet_data)
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
# Putting data into tibble
daymet_data <- as_tibble(daymet_data)
daymet_data <- row_to_names(daymet_data, row_number = 1)
# Converting data to numeric
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
View(daymet_data)
# Let's try getting Daymet data a different way, downloading it directly from the web
# Here's some documentation: https://daymet.ornl.gov/web_services#single
# Loading necessary packages
library(curl)
library(tidyverse)
library(janitor)
# Writing a function to stream Daymet data from a URL
# Function arguments:
# Latitude as string
lat <- ""
# Longitude as string
lon <- ""
# Comma-separated Daymet variables of interest as string, a selection of: dayl,prcp,srad,swe,tmax,tmin,vp
vars <- ""
# Start Date as string, in format YYYY-MM-DD
start <- ""
# End Date as string, in format YYYY-MM-DD
end <- ""
# Building URL
str_glue('https://daymet.ornl.gov/single-pixel/api/data?lat=',
lat,
'&lon=',
lon,
'&vars=',
vars,
'&start=',
start,
'&end=',
end,
sep = "")
# Building URL
url <- str_glue('https://daymet.ornl.gov/single-pixel/api/data?lat=',
lat,
'&lon=',
lon,
'&vars=',
vars,
'&start=',
start,
'&end=',
end,
sep = "")
url
# Function arguments:
# Latitude as string
lat <- "35.9621"
# Longitude as string
lon <- "-84.2916"
# Comma-separated Daymet variables of interest as string, a selection of: dayl,prcp,srad,swe,tmax,tmin,vp
vars <- "tmax"
# Start Date as string, in format YYYY-MM-DD
start <- "2020-01-01"
# End Date as string, in format YYYY-MM-DD
end <- "2020-01-01"
# Building URL
url <- str_glue('https://daymet.ornl.gov/single-pixel/api/data?lat=',
lat,
'&lon=',
lon,
'&vars=',
vars,
'&start=',
start,
'&end=',
end,
sep = "")
url
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
# Putting data into tibble
daymet_data <- as_tibble(daymet_data)
daymet_data <- row_to_names(daymet_data, row_number = 1)
# Converting data to numeric
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
View(daymet_data)
# Building URL
url <- str_glue('https://daymet.ornl.gov/single-pixel/api/data?lat=',
lat,
'&lon=',
lon,
'&vars=',
vars,
'&start=',
start,
'&end=',
end,
sep = "")
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
output
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
View(daymet_data)
# Putting data into tibble
daymet_data <- as_tibble(daymet_data, .name_repair = 'unique')
View(daymet_data)
daymet_data <- row_to_names(daymet_data, row_number = 1)
View(daymet_data)
# Converting data to numeric
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
View(daymet_data)
daymet_download <- function(lat, lon, vars, start, end){
# Building URL
url <- str_glue('https://daymet.ornl.gov/single-pixel/api/data?',
'lat=', lat,
'&lon=', lon,
'&vars=', vars,
'&start=', start,
'&end=', end,
sep = "")
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
# Putting data into tibble
daymet_data <- as_tibble(daymet_data, .name_repair = 'unique')
daymet_data <- row_to_names(daymet_data, row_number = 1)
# Converting data to numeric
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
}
# Latitude as string
lat <- "35.9621"
# Longitude as string
lon <- "-84.2916"
# Comma-separated Daymet variables of interest as string, a selection of: dayl,prcp,srad,swe,tmax,tmin,vp
vars <- "tmax"
# Start Date as string, in format YYYY-MM-DD
start <- "2020-01-01"
# End Date as string, in format YYYY-MM-DD
end <- "2020-01-01"
daymet_data <- daymet_download(lat, lon, vars, start, end)
View(daymet_data)
# Let's try getting Daymet data a different way, downloading it directly from the web
# Here's some documentation: https://daymet.ornl.gov/web_services#single
# Loading necessary packages
library(curl)
library(tidyverse)
library(janitor)
daymet_download <- function(lat, lon, vars, start, end){
# Building URL
url <- str_glue('https://daymet.ornl.gov/single-pixel/api/data?',
'lat=', lat,
'&lon=', lon,
'&vars=', vars,
'&start=', start,
'&end=', end,
sep = "")
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
# Putting data into tibble
daymet_data <- as_tibble(daymet_data, .name_repair = 'unique')
daymet_data <- row_to_names(daymet_data, row_number = 1)
# Converting data to numeric
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
}
# Running the function with specified arguments
lat <- "35.9621"
lon <- "-84.2916"
vars <- "tmax"
start <- "2020-01-01"
end <- "2020-01-01"
end <- "2020-01-02"
daymet_data <- daymet_download(lat, lon, vars, start, end)
View(daymet_data)
View(daymet_data)
