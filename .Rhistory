# Loading necessary packages
library(daymetr)
# Downloading Daymet data for a specified longitude/latitude and time period
download_daymet(site = "Oak Ridge National Laboratories",
lat = 36.0133,
lon = -84.2625,
start = 1980,
end = 1981,
internal = TRUE)
# Downloading Daymet data for a specified longitude/latitude and time period
x <- download_daymet(site = "Oak Ridge National Laboratories",
lat = 36.0133,
lon = -84.2625,
start = 1980,
end = 1981,
internal = TRUE)
View(x)
y <- x$data
View(y)
colnames(y)
# Downloading Daymet data for a specified longitude/latitude and time period
x <- download_daymet(site = "Oak Ridge National Laboratories",
lat = 36.0133,
lon = -84.2625,
start = 2020,
end = 2023,
internal = TRUE)
# Downloading Daymet data for a specified longitude/latitude and time period
x <- download_daymet(site = "Oak Ridge National Laboratories",
lat = 36.0133,
lon = -84.2625,
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE)
y <- x$data
View(y)
# Downloading Daymet data for a specified longitude/latitude and time period
x <- download_daymet(
lat = 36.0133,
lon = -84.2625,
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE)
# Downloading Daymet data for a specified longitude/latitude and time period
x <- download_daymet(
lat = 36.0133,
lon = -84.2625,
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE,
silent = TRUE)
y <- x$data
x <- download_daymet_batch(file_location = 'sample_addresses.csv',
start = 2020,
end = 2021,
internal = TRUE)
View(x)
y <- x[[1]]
View(y)
z <- y$data
View(z)
x <- download_daymet_batch(file_location = 'sample_addresses.csv',
start = 2020,
end = 2023,
internal = TRUE)
x <- download_daymet_batch(file_location = 'sample_addresses.csv',
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE)
View(x)
y <- x[[1]]
z <- y$data
View(z)
table(z$yday)
# Downloading Daymet data for a specified longitude/latitude and time period
daymet_data <- download_daymet(lat = 36.0133,
lon = -84.2625,
start = 06-01-2020,
end = 2023,
force = TRUE,
internal = TRUE,
silent = TRUE)
# Downloading Daymet data for a specified longitude/latitude and time period
daymet_data <- download_daymet(lat = 36.0133,
lon = -84.2625,
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE,
silent = TRUE)
rm(x, y, z)
View(daymet_data)
daymet_data <- daymet_data$data
View(daymet_data)
colnames(daymet_data)
table(daymet_data$yday)
# Downloading Daymet data for a specified longitude/latitude and time period
daymet_data <- download_daymet(lat = 36.0133,
lon = -84.2625,
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE,
silent = TRUE)
daymet_data <- daymet_data$data
View(daymet_data)
table(daymet_data$yday)
# Downloading Daymet data given a CSV of site name, latitude, longitude
daymet_data <- download_daymet_batch(file_location = 'sample_addresses.csv',
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE)
View(daymet_data)
# Extracting the Daymet data for the first patient
y <- daymet_data[[1]]
View(y)
y$site
assign(y$site)
?assign
assign("df", y$site)
as.data.frame(assign("df", y$site))
df <- data.frame()
assign(y$site, df)
assign(y$site, data.frame())
# Downloading Daymet data given a CSV of site name, latitude, longitude
daymet_data <- download_daymet_batch(file_location = 'sample_addresses.csv',
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE)
# Extracting the Daymet data for the first patient
data1 <- daymet_data[[1]]
assign(data1$site, data.frame())
View(patid1)
z <- data1$data
View(z)
assign(data1$site, data.frame()) <- data1$data
assign(data1$site, data.frame(data1$data))
rm(z)
# Downloading Daymet data given a CSV of site name, latitude, longitude
daymet_data <- download_daymet_batch(file_location = 'sample_addresses.csv',
start = 2020,
end = 2023,
force = TRUE,
internal = TRUE)
# Extracting the Daymet data for the first patient
assign(daymet_data[[1]]$site, data.frame(daymet_data[[1]]$data))
View(patid1)
View(patid1)
View(patid1)
# Let's try downloading Daymet data a different way, scraping it directly from the web
# Here's some documentation: https://daymet.ornl.gov/web_services#single
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-12-30&end=2020-12-30'
install.packages('RCurl')
x <- getURL(url)
# Let's try downloading Daymet data a different way, scraping it directly from the web
# Here's some documentation: https://daymet.ornl.gov/web_services#single
library(RCurl)
x <- getURL(url)
x
x <- download.file(url)
x <- curl(url)
library(curl)
x <- curl(url)
x <- url(url)
x
x <- read.csv(url)
View(x)
x <- readr::read_csv(url)
View(x)
x <- read.table(url)
x <- read.csv(url)
View(x)
x <- download.file(url, destfile = "C:\\Users\\benba\\Documents\\Defusing Disasters\\DeGAUSS\\TEST\\test.csv", method = "wget")
download.file(url, destfile = "C:\\Users\\benba\\Documents\\Defusing Disasters\\DeGAUSS\\TEST\\test.csv", method = "wget")
download.file(url, destfile = "C:\\Users\\benba\\Documents\\Defusing Disasters\\DeGAUSS\\TEST\\test.csv")
con <- curl(url)
con
open(con)
out <- readLines(con, n = 3)
out
out <- readLines(con, n = 10)
out
close(con)
con <- curl(url)
open(con)
out <- readLines(con)
close(con)
out
x <- as.data.frame(out[8:9])
View(x)
# Let's try downloading Daymet data a different way, scraping it directly from the web
# Here's some documentation: https://daymet.ornl.gov/web_services#single
# Loading necessary packages
library(curl)
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
library(tidyverse)
# Importing this file back into R, only keeping the rows that I want
daymet_data <- read_csv("Daymet Data.csv")
View(daymet_data)
?read_csv
# Importing this file back into R, only keeping the rows that I want
daymet_data <- read_csv("Daymet Data.csv", skip = 7)
View(daymet_data)
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
?download.file
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
# Downloading the file directly and saving to disk
download.file(url, destfile = "Daymet Data.csv")
# Importing this file back into R, only keeping the rows that I want
daymet_data <- read_csv("Daymet Data.csv", skip = 7)
View(daymet_data)
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
connection
open(connection)
# Streaming the data
output <- readLines(connection)
# Closing the streaming connection
close(connection)
output
str(output)
# Pulling out the data of interest
str_detect(output, "year")
output
as.data.frame(output)
# Pulling out the data of interest
str_detect(output, "year,yday")
# Pulling out the data of interest
x <- output[str_detect(output, "year,yday")]
x
# Pulling out the data of interest
x <- output[str_detect(output, "year,yday"):,]
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday\\w+$")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*\n")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*")
x
# Pulling out the data of interest
x <- str_extract(output, "year,yday.*|year,yday.*\n.*")
x
output
# Pulling out the data of interest
x <- str_extract(output, "year,yday.* \n")
x
str_detect(output, "year,yday")
output[str_detect(output, "year,yday")]
output[str_detect(output, "year,yday"):]
list(output)
# Pulling out the data of interest
output <- as.list(output)
output
x <- str_extract(output, "year,yday.*")
x
rm(x)
output[str_detect(output, "year,yday"):]
tail(output, -2)
tail(output, 2)
tail(output, 2)
rm(output, daymet_data, connection)
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
output[str_detect(output, "year,yday")]
# Pulling out the data of interest
output_length <- length(output)
output_length
data_position <- str_detect(output, "year,yday")
str_detect(data_position, TRUE)
str_detect(data_position, "TRUE")
data_position
str_locate(output, "year,yday")
str_locate_all(output, "year,yday")
str_match(output, "year,yday")
str_match_all(output, "year,yday")
data_position <- str_locate(output, "year,yday")
View(data_position)
match(output, "year,yday")
x <- str_detect(output, "year,yday")
x
match(x, TRUE)
match(TRUE, x)
# Pulling out the data of interest
output_length <- length(output)
rm(x)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail(output, 2)
head(output, 2)
tail_position <- output_length - data_position
tail_position
tail(output, 1)
tail(output, 2)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
output
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "How to")
data_string
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
tail_position
tail(output, 4)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "How to")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
output
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
daymet_data
# Splitting the data strings
str_split(daymet_data, ",")
# Splitting the data strings
x <- str_split(daymet_data, ",")
View(x)
# Splitting the data strings
daymet_data <- as_tibble(daymet_data)
rm(x)
View(daymet_data)
separate_wider_delim(daymet_data, delim = ",")
separate_wider_delim(daymet_data, cols = value, delim = ",")
separate_wider_delim(daymet_data, cols = value, names = NULL, delim = ",")
separate_wider_delim(daymet_data, cols = value, names = Var, delim = ",")
separate_wider_delim(daymet_data, cols = value, names = "Var", delim = ",")
View(daymet_data)
separate_wider_delim(daymet_data, cols = value, names = c("Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "Var9"), delim = ",")
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- as_tibble(daymet_data)
View(daymet_data)
x <- str_split(daymet_data, ",")
View(x)
daymet_data <- tail(output, tail_position)
# Splitting the data strings
x <- str_split(daymet_data, ",")
daymet_data <- as_tibble(daymet_data)
View(x)
length(x)
length(x[[1]])
daymet_data <- tail(output, tail_position)
daymet_data
# Splitting the data strings
num_values <- str_split(daymet_data[1], ",")
rm(x)
View(num_values)
# Splitting the data strings
num_values <- length(str_split(daymet_data[1], ","))
# Splitting the data strings
num_values <- length(str_split(daymet_data[1], ",")[[1]])
daymet_data <- tail(output, tail_position)
daymet_data
str_split(daymet_data[1], ",")
daymet_data[[1]]
str_split(daymet_data[[1]], ",")
length(str_split(daymet_data[[1]], ","))
daymet_data[[1]]
daymet_data[[1]]
str_split(daymet_data[[1]], ",")
str_split(daymet_data[[1]], ",", simplify = TRUE)
length(str_split(daymet_data[[1]], ",", simplify = TRUE))
str_split(daymet_data, ",", simplify = TRUE)
str_split(daymet_data, ",", simplify = TRUE)
x <- str_split(daymet_data, ",", simplify = TRUE)
View(x)
x <- as_tibble(x)
View(x)
row_to_names(x)
row_to_names(x)
library(janitor)
row_to_names(x)
?row_to_names
row_to_names(x, row_number = 1)
rm(x)
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
View(daymet_data)
daymet_data <- as_tibble(daymet_data)
View(daymet_data)
daymet_data <- row_to_names(daymet_data, row_number = 1)
View(daymet_data)
str(daymet_data)
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
str(daymet_data)
View(daymet_data)
View(daymet_data)
# Setting a URL - this can be customized with Latitude, Longitude, Variables of Interest, Start Date, and End Date
url <- 'https://daymet.ornl.gov/single-pixel/api/data?lat=35.9621&lon=-84.2916&vars=dayl,prcp,srad,swe,tmax,tmin,vp&start=2020-01-01&end=2020-01-01'
# Alternatively, streaming the data directly into R
# Opening a streaming connection
connection <- curl(url)
open(connection)
# Streaming the data as text
output <- readLines(connection)
# Closing the streaming connection
close(connection)
# Pulling out the data of interest
output_length <- length(output)
data_string <- str_detect(output, "year,yday")
data_position <- match(TRUE, data_string)
tail_position <- output_length - data_position + 1
daymet_data <- tail(output, tail_position)
# Splitting the data strings
daymet_data <- str_split(daymet_data, ",", simplify = TRUE)
# Putting data into tibble
daymet_data <- as_tibble(daymet_data)
daymet_data <- row_to_names(daymet_data, row_number = 1)
# Converting data to numeric
daymet_data <- daymet_data |>
mutate_if(is.character, as.numeric)
View(daymet_data)
